{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from datetime import date,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data', 'final', 'public')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_values, train_labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "      <td>174602.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.895454</td>\n",
       "      <td>701.410935</td>\n",
       "      <td>6261.399423</td>\n",
       "      <td>2.129254</td>\n",
       "      <td>26.437899</td>\n",
       "      <td>8.009416</td>\n",
       "      <td>5.431261</td>\n",
       "      <td>0.088613</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.034461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064558</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.024348</td>\n",
       "      <td>412.469421</td>\n",
       "      <td>3648.427229</td>\n",
       "      <td>0.728312</td>\n",
       "      <td>72.711965</td>\n",
       "      <td>4.394350</td>\n",
       "      <td>1.914698</td>\n",
       "      <td>0.284185</td>\n",
       "      <td>0.426113</td>\n",
       "      <td>0.182411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245745</td>\n",
       "      <td>0.179475</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.031733</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.072202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>3073.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>6271.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>9414.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   174602.000000   174602.000000   174602.000000        174602.000000   \n",
       "mean        13.895454      701.410935     6261.399423             2.129254   \n",
       "std          8.024348      412.469421     3648.427229             0.728312   \n",
       "min          0.000000        0.000000        1.000000             1.000000   \n",
       "25%          7.000000      350.000000     3073.000000             2.000000   \n",
       "50%         12.000000      706.000000     6271.000000             2.000000   \n",
       "75%         21.000000     1050.000000     9414.000000             2.000000   \n",
       "max         30.000000     1427.000000    12567.000000             7.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  174602.000000    174602.000000      174602.000000   \n",
       "mean       26.437899         8.009416           5.431261   \n",
       "std        72.711965         4.394350           1.914698   \n",
       "min         0.000000         1.000000           2.000000   \n",
       "25%        10.000000         5.000000           4.000000   \n",
       "50%        15.000000         7.000000           5.000000   \n",
       "75%        30.000000         9.000000           6.000000   \n",
       "max       995.000000        96.000000          32.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 174602.000000                        174602.000000   \n",
       "mean                       0.088613                             0.761589   \n",
       "std                        0.284185                             0.426113   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  ...  has_secondary_use_agriculture  \\\n",
       "count                  174602.000000  ...                  174602.000000   \n",
       "mean                        0.034461  ...                       0.064558   \n",
       "std                         0.182411  ...                       0.245745   \n",
       "min                         0.000000  ...                       0.000000   \n",
       "25%                         0.000000  ...                       0.000000   \n",
       "50%                         0.000000  ...                       0.000000   \n",
       "75%                         0.000000  ...                       0.000000   \n",
       "max                         1.000000  ...                       1.000000   \n",
       "\n",
       "       has_secondary_use_hotel  has_secondary_use_rental  \\\n",
       "count            174602.000000             174602.000000   \n",
       "mean                  0.033321                  0.007932   \n",
       "std                   0.179475                  0.088710   \n",
       "min                   0.000000                  0.000000   \n",
       "25%                   0.000000                  0.000000   \n",
       "50%                   0.000000                  0.000000   \n",
       "75%                   0.000000                  0.000000   \n",
       "max                   1.000000                  1.000000   \n",
       "\n",
       "       has_secondary_use_institution  has_secondary_use_school  \\\n",
       "count                  174602.000000             174602.000000   \n",
       "mean                        0.001008                  0.000338   \n",
       "std                         0.031733                  0.018379   \n",
       "min                         0.000000                  0.000000   \n",
       "25%                         0.000000                  0.000000   \n",
       "50%                         0.000000                  0.000000   \n",
       "75%                         0.000000                  0.000000   \n",
       "max                         1.000000                  1.000000   \n",
       "\n",
       "       has_secondary_use_industry  has_secondary_use_health_post  \\\n",
       "count               174602.000000                  174602.000000   \n",
       "mean                     0.001163                       0.000183   \n",
       "std                      0.034078                       0.013537   \n",
       "min                      0.000000                       0.000000   \n",
       "25%                      0.000000                       0.000000   \n",
       "50%                      0.000000                       0.000000   \n",
       "75%                      0.000000                       0.000000   \n",
       "max                      1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_gov_office  has_secondary_use_use_police  \\\n",
       "count                 174602.000000                 174602.000000   \n",
       "mean                       0.000137                      0.000063   \n",
       "std                        0.011723                      0.007937   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_other  \n",
       "count            174602.000000  \n",
       "mean                  0.005240  \n",
       "std                   0.072202  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                   1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'presotere' in globals():\n",
    "    del presotere\n",
    "class presotere(TransformerMixin,BaseEstimator):\n",
    "    \n",
    "    def __init__(self,caso,geocode,scaler):\n",
    "        self.lencoder_col=list([])\n",
    "        self.object_cols=list([])\n",
    "        self.number_cols = list([])\n",
    "        self.lencoder_col=list([])\n",
    "        self._caso=caso\n",
    "        self.legeo = LabelEncoder()\n",
    "        self.lencoder= list([])\n",
    "        self._sns_data=None\n",
    "        self._y=None\n",
    "        self._geocode=geocode\n",
    "        self._scaler=scaler\n",
    "        \n",
    "    def inicializamodelo(self,caso):\n",
    "\n",
    "        if caso == 1:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= list([])\n",
    "        if caso == 2:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= OneHotEncoder(handle_unknown='ignore', sparse=False)   \n",
    "        \n",
    "        \n",
    "    def transform(self,X,y=None, **kwargs):\n",
    "        print(\"Transformando \",self.get_params())\n",
    "        if self._caso == 1:\n",
    "            contador=0\n",
    "            self._sns_data=X[self.number_cols].copy()\n",
    "            for col in X[self.object_cols].columns:\n",
    "                self.lencoder.append(LabelEncoder())\n",
    "                self.lencoder[contador].fit(X[col])\n",
    "                self._sns_data[col]=self.lencoder[contador].transform(X[col])  \n",
    "                contador=contador+1\n",
    "                \n",
    "                \n",
    "        if self._caso == 2:  \n",
    "            nada = None\n",
    "            self._sns_data=None\n",
    "            nada = self.lencoder.fit_transform(X[self.object_cols])\n",
    "            co1c=0\n",
    "            self.lencoder_col=list([])\n",
    "            for co1 in self.lencoder.categories_:\n",
    "                for co2 in co1:\n",
    "                    self.lencoder_col.append(self.object_cols[co1c]+\"_\"+co2)\n",
    "                co1c=co1c+1\n",
    "            objedf=pd.DataFrame(nada,columns=self.lencoder_col,\n",
    "                                         index=X[self.object_cols].index.tolist())\n",
    "            self._sns_data=pd.concat([X[self.number_cols].copy(),objedf],axis=1)  \n",
    "\n",
    "                \n",
    "        if self._geocode>0:        \n",
    "            geo_level_1_fact=math.pow(10,int(math.log(self._sns_data['geo_level_2_id'].max(),10)+1))\n",
    "            geo_level_2_fact=math.pow(10,int(math.log(self._sns_data['geo_level_3_id'].max(),10)+1))\n",
    "            self._sns_data['geo_level_n']=  self._sns_data['geo_level_1_id']*geo_level_1_fact*geo_level_2_fact+self._sns_data['geo_level_2_id']*geo_level_2_fact+self._sns_data['geo_level_3_id']\n",
    "            self._sns_data['geo_level']=self._sns_data['geo_level_n']#.astype(np.int64).astype(str)\n",
    "            self._sns_data['geo_level_2']=self._sns_data['geo_level_n']*self._sns_data['geo_level_n']\n",
    "            self._sns_data['geo_level_cod']=self._sns_data['geo_level_n'].astype(np.int64)\n",
    "\n",
    "\n",
    "            \n",
    "            self._sns_data=self._sns_data.drop(['geo_level_n','geo_level'],axis=1)\n",
    "\n",
    "#tratamiento de age            \n",
    "#            self._sns_data['age1']=self._sns_data['age'].apply(lambda x:x  if x <200 else 200)\n",
    "#            self._sns_data['age1']=self._sns_data['age'].apply(lambda x:x  if x <200 else 200)\n",
    "#        self._sns_data['age2']=np.log(self._sns_data['age']+1)\n",
    "#        self._sns_data['age2']=(self._sns_data['age']*self._sns_data['age'])\n",
    "#        self._sns_data=self._sns_data.drop(['age'],axis=1)\n",
    "#            self._sns_data['age2']=self._sns_data['age'].apply(lambda x:0  if x <200 else 1)\n",
    "#            self._sns_data=self._sns_data.drop(['age','age1'],axis=1)\n",
    "######            \n",
    "        self._sns_data=self._sns_data.drop(['count_floors_pre_eq'],axis=1)\n",
    "        if self._scaler==\"MinMax\":\n",
    "            mi_scaler = MinMaxScaler()\n",
    "        if self._scaler==\"Standard\":\n",
    "            mi_scaler = StandardScaler()            \n",
    "        self._sns_data[list(self._sns_data.columns)]=mi_scaler.fit_transform(self._sns_data.values.astype(float))\n",
    "        lcolum_x = list(self._sns_data.columns) \n",
    "        return self._sns_data\n",
    "    \n",
    "    def fit(self,X, y=None, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if key==\"caso\":\n",
    "                self._caso=value\n",
    "            if key==\"geocode\":\n",
    "                self._geocode=value\n",
    "            if key==\"scaler\":\n",
    "                self._scaler=value\n",
    "        s = (X.dtypes == 'object')\n",
    "        self.object_cols = list(s[s].index)\n",
    "        s = (X.dtypes != 'object')        \n",
    "        self.number_cols = list(s[s].index) \n",
    "        self._y=y\n",
    "        self.inicializamodelo(self._caso)\n",
    "        self.transform(X,y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return(self._y)\n",
    "\n",
    "    def fit_transform(self,X, y=None, **kwargs):\n",
    "            miX=X.values\n",
    "            miX=miX.reshape(-1, 1)\n",
    "            self.fit(X, y, **kwargs)\n",
    "            nada=self.transform(X, **kwargs)\n",
    "            return(nada)\n",
    "        \n",
    "    def set_params(self,**kwargs):\n",
    "            for key, value in kwargs.items():\n",
    "                if key==\"caso\":\n",
    "                    self._caso=value\n",
    "                if key==\"geocode\":\n",
    "                    self._geocode=value\n",
    "                if key==\"scaler\":\n",
    "                    self._scaler=value                                 \n",
    "            return self    \n",
    "        \n",
    "    def get_params(self,**kwargs):\n",
    "        return({\"caso\":self._caso,\"geocode\":self._geocode,\"scaler\":self._scaler})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargamodelo(modelcaso):\n",
    "    global model\n",
    "    if modelcaso==1:\n",
    "        model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial',max_iter=500)\n",
    "    if modelcaso==2:    \n",
    "        model = RandomForestRegressor(max_depth=20, random_state=0,n_estimators=100)\n",
    "    if modelcaso==3:\n",
    "        model = DecisionTreeClassifier(random_state=0,max_depth=20) \n",
    "    if modelcaso==4:\n",
    "        model = MultinomialNB\n",
    "    if modelcaso==5:\n",
    "        model = DecisionTreeRegressor(random_state=0)   \n",
    "    if modelcaso==6:\n",
    "        model = SVC(gamma='auto',verbose=True,kernel='linear', probability=True)       \n",
    "    if modelcaso==7:\n",
    "        model = RandomForestClassifier(max_depth=20, random_state=0,n_estimators=100)     \n",
    "    if modelcaso==80:\n",
    "        model = XGBClassifier()   \n",
    "    if modelcaso==81:        \n",
    "        model = XGBRegressor()        \n",
    "    if modelcaso==9:    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=36, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mimodelo(RandomForestRegressor):\n",
    "    \n",
    "    def fit(self, X, y,sample_weight=None):\n",
    "#        yfinal=np.log(y)\n",
    "        yfinal=y\n",
    "        return(super().fit(X,yfinal,sample_weight))\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "#        return(np.exp(super().predict(X)).round().astype(\"int64\"))\n",
    "        return(super().predict(X).round().astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pipeline' in globals():    \n",
    "    del pipeline\n",
    "final=Pipeline(memory=None,\n",
    "     steps=[('Preprosessor', presotere(caso=1, geocode=1, scaler='MinMax')), ('Modelo', mimodelo(bootstrap=True, criterion='mse', max_depth=27, max_features='auto',\n",
    "     max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "     min_impurity_split=None, min_samples_leaf=2, min_samples_split=20,\n",
    "     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
    "     oob_score=False, random_state=0, verbose=1, warm_start=False))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n",
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7369736857405319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "final.fit(X_train,y_train)\n",
    "f1=f1_score(y_test, final.predict(X_test), average='micro') \n",
    "print(\"Score\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var body = document.body,  \n",
       "    attribs = body.attributes;\n",
       "var command = \"theNotebook = \" + \"'\"+attribs['data-notebook-name'].value+\"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var body = document.body,  \n",
    "    attribs = body.attributes;\n",
    "var command = \"theNotebook = \" + \"'\"+attribs['data-notebook-name'].value+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(DATA_DIR / 'resultados.txt','a+')\n",
    "print(theNotebook,file=f)\n",
    "print(final.steps,file=f)\n",
    "print(\"Score:\",  f1,file=f)\n",
    "print(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
