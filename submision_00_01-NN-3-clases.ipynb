{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data', 'final', 'public')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'presotere' in globals():\n",
    "    del presotere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class presotere(TransformerMixin,BaseEstimator):\n",
    "    \n",
    "    def __init__(self,caso,geocode,scaler):\n",
    "        self.lencoder_col=list([])\n",
    "        self.object_cols=list([])\n",
    "        self.number_cols = list([])\n",
    "        self.lencoder_col=list([])\n",
    "        self._caso=caso\n",
    "        self.legeo = LabelEncoder()\n",
    "        self.lencoder= list([])\n",
    "        self._sns_data=None\n",
    "        self._y=None\n",
    "        self._geocode=geocode\n",
    "        self._scaler=scaler\n",
    "        \n",
    "    def inicializamodelo(self,caso):\n",
    "\n",
    "        if caso == 1:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= list([])\n",
    "        if caso == 2:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= OneHotEncoder(handle_unknown='ignore', sparse=False)   \n",
    "        \n",
    "        \n",
    "    def transform(self,X,y=None, **kwargs):\n",
    "        print(\"Transformando \",self.get_params())\n",
    "        if self._caso == 1:\n",
    "            contador=0\n",
    "            self._sns_data=X[self.number_cols].copy()\n",
    "            for col in X[self.object_cols].columns:\n",
    "                self.lencoder.append(LabelEncoder())\n",
    "                self.lencoder[contador].fit(X[col])\n",
    "                self._sns_data[col]=self.lencoder[contador].transform(X[col])  \n",
    "                contador=contador+1\n",
    "                \n",
    "                \n",
    "        if self._caso == 2:  \n",
    "            nada = None\n",
    "            self._sns_data=None\n",
    "            nada = self.lencoder.fit_transform(X[self.object_cols])\n",
    "            co1c=0\n",
    "            self.lencoder_col=list([])\n",
    "            for co1 in self.lencoder.categories_:\n",
    "                for co2 in co1:\n",
    "                    self.lencoder_col.append(self.object_cols[co1c]+\"_\"+co2)\n",
    "                co1c=co1c+1\n",
    "            objedf=pd.DataFrame(nada,columns=self.lencoder_col,\n",
    "                                         index=X[self.object_cols].index.tolist())\n",
    "            self._sns_data=pd.concat([X[self.number_cols].copy(),objedf],axis=1)  \n",
    "\n",
    "                \n",
    "        if self._geocode>0:        \n",
    "            geo_level_1_fact=math.pow(10,int(math.log(self._sns_data['geo_level_2_id'].max(),10)+1))\n",
    "            geo_level_2_fact=math.pow(10,int(math.log(self._sns_data['geo_level_3_id'].max(),10)+1))\n",
    "            self._sns_data['geo_level_n']=  self._sns_data['geo_level_1_id']*geo_level_1_fact*geo_level_2_fact+self._sns_data['geo_level_2_id']*geo_level_2_fact+self._sns_data['geo_level_3_id']\n",
    "            self._sns_data['geo_level']=self._sns_data['geo_level_n']#.astype(np.int64).astype(str)\n",
    "            self._sns_data['geo_level_2']=self._sns_data['geo_level_n']*self._sns_data['geo_level_n']\n",
    "            self._sns_data['geo_level_cod']=self._sns_data['geo_level_n'].astype(np.int64)\n",
    "\n",
    "            self._sns_data=self._sns_data.drop(['geo_level_n','geo_level'],axis=1)\n",
    "\n",
    "        self._sns_data=self._sns_data.drop(['count_floors_pre_eq'],axis=1)\n",
    "        if self._scaler==\"MinMax\":\n",
    "            mi_scaler = MinMaxScaler()\n",
    "        if self._scaler==\"Standard\":\n",
    "            mi_scaler = StandardScaler()            \n",
    "        self._sns_data[list(self._sns_data.columns)]=mi_scaler.fit_transform(self._sns_data.values.astype(float))\n",
    "        lcolum_x = list(self._sns_data.columns) \n",
    "        return self._sns_data\n",
    "    \n",
    "    def fit(self,X, y=None, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if key==\"caso\":\n",
    "                self._caso=value\n",
    "            if key==\"geocode\":\n",
    "                self._geocode=value\n",
    "            if key==\"scaler\":\n",
    "                self._scaler=value\n",
    "        s = (X.dtypes == 'object')\n",
    "        self.object_cols = list(s[s].index)\n",
    "        s = (X.dtypes != 'object')        \n",
    "        self.number_cols = list(s[s].index) \n",
    "        self._y=y\n",
    "        self.inicializamodelo(self._caso)\n",
    "        self.transform(X,y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return(self._y)\n",
    "\n",
    "    def fit_transform(self,X, y=None, **kwargs):\n",
    "            miX=X.values\n",
    "            miX=miX.reshape(-1, 1)\n",
    "            self.fit(X, y, **kwargs)\n",
    "            nada=self.transform(X, **kwargs)\n",
    "            return(nada)\n",
    "        \n",
    "    def set_params(self,**kwargs):\n",
    "            for key, value in kwargs.items():\n",
    "                if key==\"caso\":\n",
    "                    self._caso=value\n",
    "                if key==\"geocode\":\n",
    "                    self._geocode=value\n",
    "                if key==\"scaler\":\n",
    "                    self._scaler=value                                 \n",
    "            return self    \n",
    "        \n",
    "    def get_params(self,**kwargs):\n",
    "        return({\"caso\":self._caso,\"geocode\":self._geocode,\"scaler\":self._scaler})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargamodelo(modelcaso):\n",
    "    global model\n",
    "    if modelcaso==1:\n",
    "        model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial',max_iter=500)\n",
    "    if modelcaso==2:    \n",
    "        model = RandomForestRegressor(max_depth=20, random_state=0,n_estimators=100)\n",
    "    if modelcaso==3:\n",
    "        model = DecisionTreeClassifier(random_state=0,max_depth=20) \n",
    "    if modelcaso==4:\n",
    "        model = MultinomialNB\n",
    "    if modelcaso==5:\n",
    "        model = DecisionTreeRegressor(random_state=0)   \n",
    "    if modelcaso==6:\n",
    "        model = SVC(gamma='auto',verbose=True,kernel='linear', probability=True)       \n",
    "    if modelcaso==7:\n",
    "        model = RandomForestClassifier(max_depth=20, random_state=0,n_estimators=100)     \n",
    "    if modelcaso==80:\n",
    "        model = XGBClassifier()   \n",
    "    if modelcaso==81:        \n",
    "        model = XGBRegressor()        \n",
    "    if modelcaso==9:    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=36, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mimodelo(XGBRegressor):\n",
    "    def predict(self, X):\n",
    "        return(super().predict(X).round().astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'steps' in globals():\n",
    "    del steps\n",
    "if 'pipeline' in globals():    \n",
    "    del pipeline\n",
    "steps = [('Preprosessor', presotere(caso=1,geocode=0,scaler=\"MinMax\")),\n",
    "         ('Modelo',mimodelo(max_depth=5, random_state=0,n_estimators=10,verbose=2,n_jobs=2,objective='reg:squarederror'))]\n",
    "#steps = [('Preprosessor', presotere(caso=1))]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 2, 'geocode': 5, 'scaler': 'MinMax'}\n",
      "Transformando  {'caso': 2, 'geocode': 5, 'scaler': 'MinMax'}\n",
      "{'Preprosessor__caso': [1], 'Preprosessor__geocode': [1], 'Preprosessor__scaler': ['Standard']}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'Standard'}\n",
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'Standard'}\n",
      "Best score 0.5441114961185874\n",
      "Pipeline(memory=None,\n",
      "     steps=[('Preprosessor', presotere(caso=1, geocode=1, scaler='Standard')), ('Modelo', mimodelo(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "     colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "     importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "     max_depth=5, min_child_wei...eg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "     subsample=1, verbose=2, verbosity=1))])\n"
     ]
    }
   ],
   "source": [
    "#pipeline.fit(train_values,train_labels,Preprosessor__caso=2,Preprosessor__geocode=5,Preprosessor__scaler=\"MinMax\")\n",
    "#random_grid = {'Preprosessor__caso':[1],\n",
    "#               'Preprosessor__geocode':[1],\n",
    "#               'Preprosessor__scaler':[\"Standard\"]\n",
    "#              }\n",
    "#print(random_grid)\n",
    "#grid = GridSearchCV(pipeline, param_grid=random_grid, cv=3,scoring=\"f1_micro\", verbose=2,n_jobs=-1)\n",
    "#grid.fit(train_values,train_labels )\n",
    "#print(\"Best score\",grid.best_score_)\n",
    "#print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.fit(train_values,train_labels)\n",
    "#nada=pipeline.predict(train_values)\n",
    "##test_data=pipeline.predict(test_values)\n",
    "#pvalues=test_values[['geo_level_1_id']]\n",
    "#pvalues['damage_grade']=test_data.round().astype(np.int64)\n",
    "#pvalues=pvalues.drop(['geo_level_1_id'],axis=1)\n",
    "#pvalues.to_csv(DATA_DIR / 'submission_00_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Preprosessor__caso': [1, 2], 'Preprosessor__geocode': [0, 1], 'Preprosessor__scaler': ['MinMax', 'Standard'], 'Modelo__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'Modelo__max_features': ['auto', 'sqrt'], 'Modelo__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'Modelo__min_samples_split': [2, 5, 10], 'Modelo__min_samples_leaf': [1, 2, 4], 'Modelo__bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'Preprosessor__caso':[1,2],\n",
    "               'Preprosessor__geocode':[0,1],\n",
    "               'Preprosessor__scaler':[\"MinMax\",\"Standard\"],\n",
    "               'Modelo__n_estimators': n_estimators,\n",
    "               'Modelo__max_features': max_features,\n",
    "               'Modelo__max_depth': max_depth,\n",
    "               'Modelo__min_samples_split': min_samples_split,\n",
    "               'Modelo__min_samples_leaf': min_samples_leaf,\n",
    "               'Modelo__bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=random_grid, cv=3,scoring=\"f1_micro\", verbose=2,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 34560 candidates, totalling 103680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "grid.fit(train_values,train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score\",grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
