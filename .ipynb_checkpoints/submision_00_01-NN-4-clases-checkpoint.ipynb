{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data', 'final', 'public')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'presotere' in globals():\n",
    "    del presotere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class presotere(TransformerMixin,BaseEstimator):\n",
    "    \n",
    "    def __init__(self,caso,geocode,scaler):\n",
    "        self.lencoder_col=list([])\n",
    "        self.object_cols=list([])\n",
    "        self.number_cols = list([])\n",
    "        self.lencoder_col=list([])\n",
    "        self._caso=caso\n",
    "        self.legeo = LabelEncoder()\n",
    "        self.lencoder= list([])\n",
    "        self._sns_data=None\n",
    "        self._y=None\n",
    "        self._geocode=geocode\n",
    "        self._scaler=scaler\n",
    "        \n",
    "    def inicializamodelo(self,caso):\n",
    "\n",
    "        if caso == 1:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= list([])\n",
    "        if caso == 2:\n",
    "            self.legeo = LabelEncoder()\n",
    "            self.lencoder= OneHotEncoder(handle_unknown='ignore', sparse=False)   \n",
    "        \n",
    "        \n",
    "    def transform(self,X,y=None, **kwargs):\n",
    "        print(\"Transformando \",self.get_params())\n",
    "        if self._caso == 1:\n",
    "            contador=0\n",
    "            self._sns_data=X[self.number_cols].copy()\n",
    "            for col in X[self.object_cols].columns:\n",
    "                self.lencoder.append(LabelEncoder())\n",
    "                self.lencoder[contador].fit(X[col])\n",
    "                self._sns_data[col]=self.lencoder[contador].transform(X[col])  \n",
    "                contador=contador+1\n",
    "                \n",
    "                \n",
    "        if self._caso == 2:  \n",
    "            nada = None\n",
    "            self._sns_data=None\n",
    "            nada = self.lencoder.fit_transform(X[self.object_cols])\n",
    "            co1c=0\n",
    "            self.lencoder_col=list([])\n",
    "            for co1 in self.lencoder.categories_:\n",
    "                for co2 in co1:\n",
    "                    self.lencoder_col.append(self.object_cols[co1c]+\"_\"+co2)\n",
    "                co1c=co1c+1\n",
    "            objedf=pd.DataFrame(nada,columns=self.lencoder_col,\n",
    "                                         index=X[self.object_cols].index.tolist())\n",
    "            self._sns_data=pd.concat([X[self.number_cols].copy(),objedf],axis=1)  \n",
    "\n",
    "                \n",
    "        if self._geocode>0:        \n",
    "            geo_level_1_fact=math.pow(10,int(math.log(self._sns_data['geo_level_2_id'].max(),10)+1))\n",
    "            geo_level_2_fact=math.pow(10,int(math.log(self._sns_data['geo_level_3_id'].max(),10)+1))\n",
    "            self._sns_data['geo_level_n']=  self._sns_data['geo_level_1_id']*geo_level_1_fact*geo_level_2_fact+self._sns_data['geo_level_2_id']*geo_level_2_fact+self._sns_data['geo_level_3_id']\n",
    "            self._sns_data['geo_level']=self._sns_data['geo_level_n']#.astype(np.int64).astype(str)\n",
    "            self._sns_data['geo_level_2']=self._sns_data['geo_level_n']*self._sns_data['geo_level_n']\n",
    "            self._sns_data['geo_level_cod']=self._sns_data['geo_level_n'].astype(np.int64)\n",
    "\n",
    "            self._sns_data=self._sns_data.drop(['geo_level_n','geo_level'],axis=1)\n",
    "\n",
    "        self._sns_data=self._sns_data.drop(['count_floors_pre_eq'],axis=1)\n",
    "        if self._scaler==\"MinMax\":\n",
    "            mi_scaler = MinMaxScaler()\n",
    "        if self._scaler==\"Standard\":\n",
    "            mi_scaler = StandardScaler()            \n",
    "        self._sns_data[list(self._sns_data.columns)]=mi_scaler.fit_transform(self._sns_data.values.astype(float))\n",
    "        lcolum_x = list(self._sns_data.columns) \n",
    "        return self._sns_data\n",
    "    \n",
    "    def fit(self,X, y=None, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if key==\"caso\":\n",
    "                self._caso=value\n",
    "            if key==\"geocode\":\n",
    "                self._geocode=value\n",
    "            if key==\"scaler\":\n",
    "                self._scaler=value\n",
    "        s = (X.dtypes == 'object')\n",
    "        self.object_cols = list(s[s].index)\n",
    "        s = (X.dtypes != 'object')        \n",
    "        self.number_cols = list(s[s].index) \n",
    "        self._y=y\n",
    "        self.inicializamodelo(self._caso)\n",
    "        self.transform(X,y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return(self._y)\n",
    "\n",
    "    def fit_transform(self,X, y=None, **kwargs):\n",
    "            miX=X.values\n",
    "            miX=miX.reshape(-1, 1)\n",
    "            self.fit(X, y, **kwargs)\n",
    "            nada=self.transform(X, **kwargs)\n",
    "            return(nada)\n",
    "        \n",
    "    def set_params(self,**kwargs):\n",
    "            for key, value in kwargs.items():\n",
    "                if key==\"caso\":\n",
    "                    self._caso=value\n",
    "                if key==\"geocode\":\n",
    "                    self._geocode=value\n",
    "                if key==\"scaler\":\n",
    "                    self._scaler=value                                 \n",
    "            return self    \n",
    "        \n",
    "    def get_params(self,**kwargs):\n",
    "        return({\"caso\":self._caso,\"geocode\":self._geocode,\"scaler\":self._scaler})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargamodelo(modelcaso):\n",
    "    global model\n",
    "    if modelcaso==1:\n",
    "        model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial',max_iter=500)\n",
    "    if modelcaso==2:    \n",
    "        model = RandomForestRegressor(max_depth=20, random_state=0,n_estimators=100)\n",
    "    if modelcaso==3:\n",
    "        model = DecisionTreeClassifier(random_state=0,max_depth=20) \n",
    "    if modelcaso==4:\n",
    "        model = MultinomialNB\n",
    "    if modelcaso==5:\n",
    "        model = DecisionTreeRegressor(random_state=0)   \n",
    "    if modelcaso==6:\n",
    "        model = SVC(gamma='auto',verbose=True,kernel='linear', probability=True)       \n",
    "    if modelcaso==7:\n",
    "        model = RandomForestClassifier(max_depth=20, random_state=0,n_estimators=100)     \n",
    "    if modelcaso==80:\n",
    "        model = XGBClassifier()   \n",
    "    if modelcaso==81:        \n",
    "        model = XGBRegressor()        \n",
    "    if modelcaso==9:    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=36, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mimodelo(RandomForestRegressor):\n",
    "    def predict(self, X):\n",
    "        t = super().predict(X)\n",
    "        return(t.round().astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'steps' in globals():\n",
    "    del steps\n",
    "if 'pipeline' in globals():    \n",
    "    del pipeline\n",
    "#steps = [('Preprosessor', presotere(caso=1,geocode=0,scaler=\"MinMax\")),\n",
    "#         ('Modelo',mimodelo(max_depth=5, random_state=0,n_estimators=10,verbose=2,n_jobs=2,objective='reg:squarederror'))]\n",
    "steps = [('Preprosessor', presotere(caso=1,geocode=1,scaler=\"MinMax\")),\n",
    "         ('Modelo',mimodelo(max_depth=5, random_state=0,n_estimators=10,verbose=2,n_jobs=2))]\n",
    "#steps = [('Preprosessor', presotere(caso=1))]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n",
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Preprosessor__caso': [1], 'Preprosessor__geocode': [1], 'Preprosessor__scaler': ['Standard']}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 568, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 605, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 635, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 720, in f1_score\n    sample_weight=sample_weight)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 834, in fbeta_score\n    sample_weight=sample_weight)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1031, in precision_recall_fscore_support\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 81, in _check_targets\n    \"and {1} targets\".format(type_true, type_pred))\nValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4c3ee3b423a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1_micro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best score\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "pipeline.fit(train_values,train_labels,Preprosessor__caso=1,Preprosessor__geocode=1,Preprosessor__scaler=\"MinMax\")\n",
    "random_grid = {'Preprosessor__caso':[1],\n",
    "               'Preprosessor__geocode':[1],\n",
    "               'Preprosessor__scaler':[\"Standard\"]\n",
    "              }\n",
    "print(random_grid)\n",
    "grid = GridSearchCV(pipeline, param_grid=random_grid, cv=3,scoring=\"f1_micro\", verbose=2,n_jobs=-1)\n",
    "grid.fit(train_values,train_labels )\n",
    "print(\"Best score\",grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n",
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'MinMax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(train_values,train_labels)\n",
    "nada=pipeline.predict(train_values)\n",
    "##test_data=pipeline.predict(test_values)\n",
    "#pvalues=test_values[['geo_level_1_id']]\n",
    "#pvalues['damage_grade']=test_data.round().astype(np.int64)\n",
    "#pvalues=pvalues.drop(['geo_level_1_id'],axis=1)\n",
    "#pvalues.to_csv(DATA_DIR / 'submission_00_05.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.scatterplot(train_values.index,nada)\n",
    "nada1=pd.DataFrame(nada,columns=['result'])\n",
    "nada1['llog']=np.log(nada1['result'])\n",
    "sns.distplot(nada1, rug=True, hist=False)\n",
    "#nada1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-64d64f0421ad>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-64d64f0421ad>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pnada=\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(nada).to_csv(DATA_DIR / 'nada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'Preprosessor__caso':[1,2],\n",
    "               'Preprosessor__geocode':[0,1],\n",
    "               'Preprosessor__scaler':[\"MinMax\",\"Standard\"],\n",
    "               'Modelo__n_estimators': n_estimators,\n",
    "               'Modelo__max_features': max_features,\n",
    "               'Modelo__max_depth': max_depth,\n",
    "               'Modelo__min_samples_split': min_samples_split,\n",
    "               'Modelo__min_samples_leaf': min_samples_leaf,\n",
    "               'Modelo__bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=random_grid, cv=3,scoring=\"f1_micro\", verbose=2,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(train_values,train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score\",grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'Preprosessor__caso':[1,2],\n",
    "               'Preprosessor__geocode':[0,1],\n",
    "               'Preprosessor__scaler':[\"MinMax\",\"Standard\"],\n",
    "               'Modelo__n_estimators':  sp_randint(200, 600),\n",
    "               'Modelo__max_features': max_features,\n",
    "               'Modelo__max_depth': sp_randint(10, 110),\n",
    "               'Modelo__min_samples_split': min_samples_split,\n",
    "               'Modelo__min_samples_leaf': min_samples_leaf,\n",
    "               'Modelo__bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = RandomizedSearchCV(pipeline,  param_distributions=random_grid, cv=3,scoring=\"f1_micro\", verbose=2,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed: 67.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 0, 'scaler': 'Standard'}\n",
      "Transformando  {'caso': 1, 'geocode': 0, 'scaler': 'Standard'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 336building tree 2 of 336\n",
      "\n",
      "building tree 3 of 336\n",
      "building tree 4 of 336\n",
      "building tree 5 of 336\n",
      "building tree 6 of 336\n",
      "building tree 7 of 336\n",
      "building tree 8 of 336\n",
      "building tree 9 of 336\n",
      "building tree 10 of 336\n",
      "building tree 11 of 336\n",
      "building tree 12 of 336\n",
      "building tree 13 of 336\n",
      "building tree 14 of 336\n",
      "building tree 15 of 336\n",
      "building tree 16 of 336\n",
      "building tree 17 of 336\n",
      "building tree 18 of 336\n",
      "building tree 19 of 336\n",
      "building tree 20 of 336\n",
      "building tree 21 of 336\n",
      "building tree 22 of 336\n",
      "building tree 23 of 336\n",
      "building tree 24 of 336\n",
      "building tree 25 of 336\n",
      "building tree 26 of 336\n",
      "building tree 27 of 336\n",
      "building tree 28 of 336\n",
      "building tree 29 of 336\n",
      "building tree 30 of 336\n",
      "building tree 31 of 336\n",
      "building tree 32 of 336\n",
      "building tree 33 of 336\n",
      "building tree 34 of 336\n",
      "building tree 35 of 336\n",
      "building tree 36 of 336\n",
      "building tree 37 of 336\n",
      "building tree 38 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   33.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 336\n",
      "building tree 40 of 336\n",
      "building tree 41 of 336\n",
      "building tree 42 of 336\n",
      "building tree 43 of 336\n",
      "building tree 44 of 336\n",
      "building tree 45 of 336\n",
      "building tree 46 of 336\n",
      "building tree 47 of 336\n",
      "building tree 48 of 336\n",
      "building tree 49 of 336\n",
      "building tree 50 of 336\n",
      "building tree 51 of 336\n",
      "building tree 52 of 336\n",
      "building tree 53 of 336\n",
      "building tree 54 of 336\n",
      "building tree 55 of 336\n",
      "building tree 56 of 336\n",
      "building tree 57 of 336\n",
      "building tree 58 of 336\n",
      "building tree 59 of 336\n",
      "building tree 60 of 336\n",
      "building tree 61 of 336\n",
      "building tree 62 of 336\n",
      "building tree 63 of 336\n",
      "building tree 64 of 336\n",
      "building tree 65 of 336\n",
      "building tree 66 of 336\n",
      "building tree 67 of 336\n",
      "building tree 68 of 336\n",
      "building tree 69 of 336\n",
      "building tree 70 of 336\n",
      "building tree 71 of 336\n",
      "building tree 72 of 336\n",
      "building tree 73 of 336\n",
      "building tree 74 of 336\n",
      "building tree 75 of 336\n",
      "building tree 76 of 336\n",
      "building tree 77 of 336\n",
      "building tree 78 of 336\n",
      "building tree 79 of 336\n",
      "building tree 80 of 336\n",
      "building tree 81 of 336\n",
      "building tree 82 of 336\n",
      "building tree 83 of 336\n",
      "building tree 84 of 336\n",
      "building tree 85 of 336\n",
      "building tree 86 of 336\n",
      "building tree 87 of 336\n",
      "building tree 88 of 336\n",
      "building tree 89 of 336\n",
      "building tree 90 of 336\n",
      "building tree 91 of 336\n",
      "building tree 92 of 336\n",
      "building tree 93 of 336\n",
      "building tree 94 of 336\n",
      "building tree 95 of 336\n",
      "building tree 96 of 336\n",
      "building tree 97 of 336\n",
      "building tree 98 of 336\n",
      "building tree 99 of 336\n",
      "building tree 100 of 336\n",
      "building tree 101 of 336\n",
      "building tree 102 of 336\n",
      "building tree 103 of 336\n",
      "building tree 104 of 336\n",
      "building tree 105 of 336\n",
      "building tree 106 of 336\n",
      "building tree 107 of 336building tree 108 of 336\n",
      "\n",
      "building tree 109 of 336\n",
      "building tree 110 of 336\n",
      "building tree 111 of 336\n",
      "building tree 112 of 336\n",
      "building tree 113 of 336\n",
      "building tree 114 of 336\n",
      "building tree 115 of 336\n",
      "building tree 116 of 336\n",
      "building tree 117 of 336\n",
      "building tree 118 of 336\n",
      "building tree 119 of 336\n",
      "building tree 120 of 336\n",
      "building tree 121 of 336\n",
      "building tree 122 of 336\n",
      "building tree 123 of 336\n",
      "building tree 124 of 336\n",
      "building tree 125 of 336\n",
      "building tree 126 of 336\n",
      "building tree 127 of 336\n",
      "building tree 128 of 336\n",
      "building tree 129 of 336\n",
      "building tree 130 of 336\n",
      "building tree 131 of 336\n",
      "building tree 132 of 336\n",
      "building tree 133 of 336\n",
      "building tree 134 of 336\n",
      "building tree 135 of 336building tree 136 of 336\n",
      "\n",
      "building tree 137 of 336\n",
      "building tree 138 of 336\n",
      "building tree 139 of 336\n",
      "building tree 140 of 336\n",
      "building tree 141 of 336\n",
      "building tree 142 of 336\n",
      "building tree 143 of 336\n",
      "building tree 144 of 336\n",
      "building tree 145 of 336\n",
      "building tree 146 of 336\n",
      "building tree 147 of 336building tree 148 of 336\n",
      "\n",
      "building tree 149 of 336\n",
      "building tree 150 of 336\n",
      "building tree 151 of 336building tree 152 of 336\n",
      "\n",
      "building tree 153 of 336\n",
      "building tree 154 of 336\n",
      "building tree 155 of 336\n",
      "building tree 156 of 336\n",
      "building tree 157 of 336\n",
      "building tree 158 of 336\n",
      "building tree 159 of 336\n",
      "building tree 160 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 161 of 336\n",
      "building tree 162 of 336\n",
      "building tree 163 of 336\n",
      "building tree 164 of 336\n",
      "building tree 165 of 336\n",
      "building tree 166 of 336\n",
      "building tree 167 of 336\n",
      "building tree 168 of 336\n",
      "building tree 169 of 336\n",
      "building tree 170 of 336\n",
      "building tree 171 of 336\n",
      "building tree 172 of 336\n",
      "building tree 173 of 336\n",
      "building tree 174 of 336\n",
      "building tree 175 of 336\n",
      "building tree 176 of 336\n",
      "building tree 177 of 336\n",
      "building tree 178 of 336\n",
      "building tree 179 of 336\n",
      "building tree 180 of 336\n",
      "building tree 181 of 336\n",
      "building tree 182 of 336\n",
      "building tree 183 of 336\n",
      "building tree 184 of 336\n",
      "building tree 185 of 336\n",
      "building tree 186 of 336\n",
      "building tree 187 of 336\n",
      "building tree 188 of 336\n",
      "building tree 189 of 336\n",
      "building tree 190 of 336\n",
      "building tree 191 of 336\n",
      "building tree 192 of 336\n",
      "building tree 193 of 336\n",
      "building tree 194 of 336\n",
      "building tree 195 of 336\n",
      "building tree 196 of 336\n",
      "building tree 197 of 336\n",
      "building tree 198 of 336\n",
      "building tree 199 of 336\n",
      "building tree 200 of 336\n",
      "building tree 201 of 336\n",
      "building tree 202 of 336\n",
      "building tree 203 of 336\n",
      "building tree 204 of 336\n",
      "building tree 205 of 336\n",
      "building tree 206 of 336\n",
      "building tree 207 of 336\n",
      "building tree 208 of 336\n",
      "building tree 209 of 336\n",
      "building tree 210 of 336\n",
      "building tree 211 of 336\n",
      "building tree 212 of 336\n",
      "building tree 213 of 336\n",
      "building tree 214 of 336\n",
      "building tree 215 of 336\n",
      "building tree 216 of 336\n",
      "building tree 217 of 336\n",
      "building tree 218 of 336\n",
      "building tree 219 of 336\n",
      "building tree 220 of 336\n",
      "building tree 221 of 336\n",
      "building tree 222 of 336\n",
      "building tree 223 of 336\n",
      "building tree 224 of 336\n",
      "building tree 225 of 336\n",
      "building tree 226 of 336\n",
      "building tree 227 of 336\n",
      "building tree 228 of 336\n",
      "building tree 229 of 336\n",
      "building tree 230 of 336\n",
      "building tree 231 of 336\n",
      "building tree 232 of 336\n",
      "building tree 233 of 336\n",
      "building tree 234 of 336\n",
      "building tree 235 of 336\n",
      "building tree 236 of 336\n",
      "building tree 237 of 336\n",
      "building tree 238 of 336\n",
      "building tree 239 of 336\n",
      "building tree 240 of 336\n",
      "building tree 241 of 336\n",
      "building tree 242 of 336\n",
      "building tree 243 of 336\n",
      "building tree 244 of 336\n",
      "building tree 245 of 336\n",
      "building tree 246 of 336\n",
      "building tree 247 of 336\n",
      "building tree 248 of 336\n",
      "building tree 249 of 336\n",
      "building tree 250 of 336\n",
      "building tree 251 of 336\n",
      "building tree 252 of 336\n",
      "building tree 253 of 336\n",
      "building tree 254 of 336\n",
      "building tree 255 of 336\n",
      "building tree 256 of 336\n",
      "building tree 257 of 336\n",
      "building tree 258 of 336\n",
      "building tree 259 of 336\n",
      "building tree 260 of 336\n",
      "building tree 261 of 336\n",
      "building tree 262 of 336\n",
      "building tree 263 of 336\n",
      "building tree 264 of 336\n",
      "building tree 265 of 336\n",
      "building tree 266 of 336\n",
      "building tree 267 of 336\n",
      "building tree 268 of 336\n",
      "building tree 269 of 336\n",
      "building tree 270 of 336\n",
      "building tree 271 of 336\n",
      "building tree 272 of 336\n",
      "building tree 273 of 336\n",
      "building tree 274 of 336\n",
      "building tree 275 of 336\n",
      "building tree 276 of 336\n",
      "building tree 277 of 336\n",
      "building tree 278 of 336\n",
      "building tree 279 of 336\n",
      "building tree 280 of 336\n",
      "building tree 281 of 336\n",
      "building tree 282 of 336\n",
      "building tree 283 of 336\n",
      "building tree 284 of 336\n",
      "building tree 285 of 336\n",
      "building tree 286 of 336\n",
      "building tree 287 of 336\n",
      "building tree 288 of 336\n",
      "building tree 289 of 336\n",
      "building tree 290 of 336\n",
      "building tree 291 of 336\n",
      "building tree 292 of 336\n",
      "building tree 293 of 336\n",
      "building tree 294 of 336\n",
      "building tree 295 of 336\n",
      "building tree 296 of 336\n",
      "building tree 297 of 336\n",
      "building tree 298 of 336\n",
      "building tree 299 of 336\n",
      "building tree 300 of 336\n",
      "building tree 301 of 336\n",
      "building tree 302 of 336\n",
      "building tree 303 of 336\n",
      "building tree 304 of 336\n",
      "building tree 305 of 336\n",
      "building tree 306 of 336\n",
      "building tree 307 of 336\n",
      "building tree 308 of 336\n",
      "building tree 309 of 336\n",
      "building tree 310 of 336\n",
      "building tree 311 of 336\n",
      "building tree 312 of 336\n",
      "building tree 313 of 336\n",
      "building tree 314 of 336\n",
      "building tree 315 of 336\n",
      "building tree 316 of 336\n",
      "building tree 317 of 336\n",
      "building tree 318 of 336\n",
      "building tree 319 of 336\n",
      "building tree 320 of 336\n",
      "building tree 321 of 336\n",
      "building tree 322 of 336\n",
      "building tree 323 of 336\n",
      "building tree 324 of 336\n",
      "building tree 325 of 336\n",
      "building tree 326 of 336\n",
      "building tree 327 of 336\n",
      "building tree 328 of 336\n",
      "building tree 329 of 336\n",
      "building tree 330 of 336\n",
      "building tree 331 of 336\n",
      "building tree 332 of 336\n",
      "building tree 333 of 336\n",
      "building tree 334 of 336\n",
      "building tree 335 of 336\n",
      "building tree 336 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 336 out of 336 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('Preprosessor', presotere(caso=1, geocode=1, scaler='MinMax')), ('Modelo', mimodelo(bootstrap=True, criterion='mse', max_depth=5, max_features='auto',\n",
       "     max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "     min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
       "     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "     oob_score=False, random_state=0, verbose=2, warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=2,\n",
       "          param_distributions={'Preprosessor__caso': [1, 2], 'Preprosessor__geocode': [0, 1], 'Preprosessor__scaler': ['MinMax', 'Standard'], 'Modelo__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000157B3400>, 'Modelo__max_features': ['auto', 'sqrt'], 'Modelo__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000157B3550>, 'Modelo__min_samples_split': [2, 5, 10], 'Modelo__min_samples_leaf': [1, 2, 4], 'Modelo__bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train_values,train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.7343256549284155\n",
      "Pipeline(memory=None,\n",
      "     steps=[('Preprosessor', presotere(caso=1, geocode=0, scaler='Standard')), ('Modelo', mimodelo(bootstrap=True, criterion='mse', max_depth=27, max_features='auto',\n",
      "     max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "     min_impurity_split=None, min_samples_leaf=2, min_samples_split=10,\n",
      "     min_weight_fraction_leaf=0.0, n_estimators=336, n_jobs=2,\n",
      "     oob_score=False, random_state=0, verbose=2, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score\",grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_Modelo__bootstrap</th>\n",
       "      <th>param_Modelo__max_depth</th>\n",
       "      <th>param_Modelo__max_features</th>\n",
       "      <th>param_Modelo__min_samples_leaf</th>\n",
       "      <th>param_Modelo__min_samples_split</th>\n",
       "      <th>param_Modelo__n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235.127333</td>\n",
       "      <td>7.645898</td>\n",
       "      <td>6.436000</td>\n",
       "      <td>0.601981</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>auto</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735354</td>\n",
       "      <td>0.735561</td>\n",
       "      <td>0.734326</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862266</td>\n",
       "      <td>0.861685</td>\n",
       "      <td>0.861299</td>\n",
       "      <td>0.861750</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.486667</td>\n",
       "      <td>1.487176</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.401159</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733409</td>\n",
       "      <td>0.733086</td>\n",
       "      <td>0.732933</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>2</td>\n",
       "      <td>0.796770</td>\n",
       "      <td>0.795958</td>\n",
       "      <td>0.796171</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395.281333</td>\n",
       "      <td>13.183942</td>\n",
       "      <td>7.351667</td>\n",
       "      <td>1.113255</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727411</td>\n",
       "      <td>0.727204</td>\n",
       "      <td>0.725803</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>3</td>\n",
       "      <td>0.779738</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.777142</td>\n",
       "      <td>0.778468</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.577333</td>\n",
       "      <td>5.986018</td>\n",
       "      <td>9.420000</td>\n",
       "      <td>0.387433</td>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722576</td>\n",
       "      <td>0.721574</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>4</td>\n",
       "      <td>0.841689</td>\n",
       "      <td>0.841666</td>\n",
       "      <td>0.840895</td>\n",
       "      <td>0.841417</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.334333</td>\n",
       "      <td>1.519398</td>\n",
       "      <td>10.214333</td>\n",
       "      <td>0.421945</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.721379</td>\n",
       "      <td>0.721152</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841505</td>\n",
       "      <td>0.841712</td>\n",
       "      <td>0.840947</td>\n",
       "      <td>0.841388</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123.782667</td>\n",
       "      <td>2.410511</td>\n",
       "      <td>11.933667</td>\n",
       "      <td>0.440692</td>\n",
       "      <td>False</td>\n",
       "      <td>78</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719168</td>\n",
       "      <td>0.719583</td>\n",
       "      <td>0.717952</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.920637</td>\n",
       "      <td>0.919906</td>\n",
       "      <td>0.920580</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.124000</td>\n",
       "      <td>1.857561</td>\n",
       "      <td>10.812333</td>\n",
       "      <td>0.551317</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711018</td>\n",
       "      <td>0.710581</td>\n",
       "      <td>0.708512</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>7</td>\n",
       "      <td>0.836094</td>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.835127</td>\n",
       "      <td>0.835229</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.133333</td>\n",
       "      <td>1.384094</td>\n",
       "      <td>5.482667</td>\n",
       "      <td>0.301841</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.694752</td>\n",
       "      <td>0.694986</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>8</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.776302</td>\n",
       "      <td>0.773211</td>\n",
       "      <td>0.775413</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>519.631333</td>\n",
       "      <td>50.331512</td>\n",
       "      <td>11.845666</td>\n",
       "      <td>2.213254</td>\n",
       "      <td>False</td>\n",
       "      <td>107</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683689</td>\n",
       "      <td>0.685796</td>\n",
       "      <td>0.684157</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>9</td>\n",
       "      <td>0.840037</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.839841</td>\n",
       "      <td>0.839941</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535.321333</td>\n",
       "      <td>19.132036</td>\n",
       "      <td>12.481667</td>\n",
       "      <td>0.717868</td>\n",
       "      <td>False</td>\n",
       "      <td>96</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683585</td>\n",
       "      <td>0.685796</td>\n",
       "      <td>0.684099</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>10</td>\n",
       "      <td>0.840014</td>\n",
       "      <td>0.839916</td>\n",
       "      <td>0.839824</td>\n",
       "      <td>0.839918</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     235.127333      7.645898         6.436000        0.601981   \n",
       "7      78.486667      1.487176         6.750000        0.401159   \n",
       "1     395.281333     13.183942         7.351667        1.113255   \n",
       "5      92.577333      5.986018         9.420000        0.387433   \n",
       "8     100.334333      1.519398        10.214333        0.421945   \n",
       "3     123.782667      2.410511        11.933667        0.440692   \n",
       "2     121.124000      1.857561        10.812333        0.551317   \n",
       "6      86.133333      1.384094         5.482667        0.301841   \n",
       "9     519.631333     50.331512        11.845666        2.213254   \n",
       "4     535.321333     19.132036        12.481667        0.717868   \n",
       "\n",
       "  param_Modelo__bootstrap param_Modelo__max_depth param_Modelo__max_features  \\\n",
       "0                    True                      27                       auto   \n",
       "7                    True                      55                       sqrt   \n",
       "1                    True                      17                       auto   \n",
       "5                    True                      81                       sqrt   \n",
       "8                    True                      78                       sqrt   \n",
       "3                   False                      78                       sqrt   \n",
       "2                    True                      76                       sqrt   \n",
       "6                   False                      20                       sqrt   \n",
       "9                   False                     107                       auto   \n",
       "4                   False                      96                       auto   \n",
       "\n",
       "  param_Modelo__min_samples_leaf param_Modelo__min_samples_split  \\\n",
       "0                              2                              10   \n",
       "7                              4                               5   \n",
       "1                              4                               5   \n",
       "5                              2                               5   \n",
       "8                              2                               5   \n",
       "3                              1                              10   \n",
       "2                              2                               5   \n",
       "6                              1                               5   \n",
       "9                              4                               2   \n",
       "4                              4                               5   \n",
       "\n",
       "  param_Modelo__n_estimators  ... split1_test_score split2_test_score  \\\n",
       "0                        336  ...          0.735354          0.735561   \n",
       "7                        389  ...          0.733409          0.733086   \n",
       "1                        404  ...          0.727411          0.727204   \n",
       "5                        428  ...          0.722576          0.721574   \n",
       "8                        492  ...          0.722300          0.721379   \n",
       "3                        358  ...          0.719168          0.719583   \n",
       "2                        501  ...          0.711018          0.710581   \n",
       "6                        387  ...          0.695776          0.694752   \n",
       "9                        567  ...          0.683689          0.685796   \n",
       "4                        525  ...          0.683585          0.685796   \n",
       "\n",
       "  mean_test_score std_test_score  rank_test_score  split0_train_score  \\\n",
       "0        0.734326       0.001603                1            0.862266   \n",
       "7        0.732933       0.000464                2            0.796770   \n",
       "1        0.725803       0.002129                3            0.779738   \n",
       "5        0.721302       0.001167                4            0.841689   \n",
       "8        0.721152       0.001042                5            0.841505   \n",
       "3        0.717952       0.002020                6            0.921196   \n",
       "2        0.708512       0.003239                7            0.836094   \n",
       "6        0.694986       0.000574                8            0.776728   \n",
       "9        0.684157       0.001194                9            0.840037   \n",
       "4        0.684099       0.001230               10            0.840014   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.861685            0.861299          0.861750         0.000397  \n",
       "7            0.795958            0.796171          0.796300         0.000344  \n",
       "1            0.778523            0.777142          0.778468         0.001061  \n",
       "5            0.841666            0.840895          0.841417         0.000369  \n",
       "8            0.841712            0.840947          0.841388         0.000323  \n",
       "3            0.920637            0.919906          0.920580         0.000528  \n",
       "2            0.834465            0.835127          0.835229         0.000669  \n",
       "6            0.776302            0.773211          0.775413         0.001567  \n",
       "9            0.839945            0.839841          0.839941         0.000080  \n",
       "4            0.839916            0.839824          0.839918         0.000078  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=Pipeline(memory=None,\n",
    "     steps=[('Preprosessor', presotere(caso=1, geocode=1, scaler='Standard')), ('Modelo', mimodelo(bootstrap=True, criterion='mse', max_depth=27, max_features='auto',\n",
    "     max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "     min_impurity_split=None, min_samples_leaf=2, min_samples_split=20,\n",
    "     min_weight_fraction_leaf=0.0, n_estimators=336, n_jobs=2,\n",
    "     oob_score=False, random_state=0, verbose=2, warm_start=False))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'Standard'}\n",
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'Standard'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 336building tree 2 of 336\n",
      "\n",
      "building tree 3 of 336\n",
      "building tree 4 of 336\n",
      "building tree 5 of 336\n",
      "building tree 6 of 336\n",
      "building tree 7 of 336\n",
      "building tree 8 of 336\n",
      "building tree 9 of 336\n",
      "building tree 10 of 336\n",
      "building tree 11 of 336\n",
      "building tree 12 of 336\n",
      "building tree 13 of 336\n",
      "building tree 14 of 336\n",
      "building tree 15 of 336\n",
      "building tree 16 of 336\n",
      "building tree 17 of 336\n",
      "building tree 18 of 336\n",
      "building tree 19 of 336\n",
      "building tree 20 of 336\n",
      "building tree 21 of 336\n",
      "building tree 22 of 336\n",
      "building tree 23 of 336\n",
      "building tree 24 of 336\n",
      "building tree 25 of 336\n",
      "building tree 26 of 336\n",
      "building tree 27 of 336\n",
      "building tree 28 of 336\n",
      "building tree 29 of 336\n",
      "building tree 30 of 336\n",
      "building tree 31 of 336\n",
      "building tree 32 of 336\n",
      "building tree 33 of 336\n",
      "building tree 34 of 336\n",
      "building tree 35 of 336\n",
      "building tree 36 of 336\n",
      "building tree 37 of 336\n",
      "building tree 38 of 336\n",
      "building tree 39 of 336\n",
      "building tree 40 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   38.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 41 of 336\n",
      "building tree 42 of 336\n",
      "building tree 43 of 336\n",
      "building tree 44 of 336\n",
      "building tree 45 of 336\n",
      "building tree 46 of 336\n",
      "building tree 47 of 336\n",
      "building tree 48 of 336\n",
      "building tree 49 of 336\n",
      "building tree 50 of 336\n",
      "building tree 51 of 336\n",
      "building tree 52 of 336\n",
      "building tree 53 of 336\n",
      "building tree 54 of 336\n",
      "building tree 55 of 336\n",
      "building tree 56 of 336\n",
      "building tree 57 of 336\n",
      "building tree 58 of 336\n",
      "building tree 59 of 336\n",
      "building tree 60 of 336\n",
      "building tree 61 of 336\n",
      "building tree 62 of 336\n",
      "building tree 63 of 336\n",
      "building tree 64 of 336\n",
      "building tree 65 of 336\n",
      "building tree 66 of 336\n",
      "building tree 67 of 336\n",
      "building tree 68 of 336\n",
      "building tree 69 of 336\n",
      "building tree 70 of 336\n",
      "building tree 71 of 336\n",
      "building tree 72 of 336\n",
      "building tree 73 of 336\n",
      "building tree 74 of 336\n",
      "building tree 75 of 336\n",
      "building tree 76 of 336\n",
      "building tree 77 of 336\n",
      "building tree 78 of 336\n",
      "building tree 79 of 336\n",
      "building tree 80 of 336\n",
      "building tree 81 of 336\n",
      "building tree 82 of 336\n",
      "building tree 83 of 336\n",
      "building tree 84 of 336\n",
      "building tree 85 of 336\n",
      "building tree 86 of 336\n",
      "building tree 87 of 336\n",
      "building tree 88 of 336\n",
      "building tree 89 of 336\n",
      "building tree 90 of 336\n",
      "building tree 91 of 336\n",
      "building tree 92 of 336\n",
      "building tree 93 of 336\n",
      "building tree 94 of 336\n",
      "building tree 95 of 336\n",
      "building tree 96 of 336\n",
      "building tree 97 of 336\n",
      "building tree 98 of 336\n",
      "building tree 99 of 336\n",
      "building tree 100 of 336\n",
      "building tree 101 of 336\n",
      "building tree 102 of 336\n",
      "building tree 103 of 336\n",
      "building tree 104 of 336\n",
      "building tree 105 of 336\n",
      "building tree 106 of 336\n",
      "building tree 107 of 336\n",
      "building tree 108 of 336\n",
      "building tree 109 of 336\n",
      "building tree 110 of 336\n",
      "building tree 111 of 336\n",
      "building tree 112 of 336\n",
      "building tree 113 of 336\n",
      "building tree 114 of 336\n",
      "building tree 115 of 336\n",
      "building tree 116 of 336\n",
      "building tree 117 of 336\n",
      "building tree 118 of 336\n",
      "building tree 119 of 336\n",
      "building tree 120 of 336\n",
      "building tree 121 of 336\n",
      "building tree 122 of 336\n",
      "building tree 123 of 336\n",
      "building tree 124 of 336\n",
      "building tree 125 of 336\n",
      "building tree 126 of 336\n",
      "building tree 127 of 336\n",
      "building tree 128 of 336\n",
      "building tree 129 of 336\n",
      "building tree 130 of 336\n",
      "building tree 131 of 336\n",
      "building tree 132 of 336\n",
      "building tree 133 of 336\n",
      "building tree 134 of 336\n",
      "building tree 135 of 336\n",
      "building tree 136 of 336\n",
      "building tree 137 of 336\n",
      "building tree 138 of 336\n",
      "building tree 139 of 336\n",
      "building tree 140 of 336\n",
      "building tree 141 of 336\n",
      "building tree 142 of 336\n",
      "building tree 143 of 336\n",
      "building tree 144 of 336\n",
      "building tree 145 of 336\n",
      "building tree 146 of 336\n",
      "building tree 147 of 336\n",
      "building tree 148 of 336\n",
      "building tree 149 of 336\n",
      "building tree 150 of 336\n",
      "building tree 151 of 336\n",
      "building tree 152 of 336\n",
      "building tree 153 of 336\n",
      "building tree 154 of 336\n",
      "building tree 155 of 336\n",
      "building tree 156 of 336\n",
      "building tree 157 of 336\n",
      "building tree 158 of 336\n",
      "building tree 159 of 336\n",
      "building tree 160 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 161 of 336\n",
      "building tree 162 of 336\n",
      "building tree 163 of 336\n",
      "building tree 164 of 336\n",
      "building tree 165 of 336\n",
      "building tree 166 of 336\n",
      "building tree 167 of 336\n",
      "building tree 168 of 336\n",
      "building tree 169 of 336\n",
      "building tree 170 of 336\n",
      "building tree 171 of 336\n",
      "building tree 172 of 336\n",
      "building tree 173 of 336\n",
      "building tree 174 of 336\n",
      "building tree 175 of 336\n",
      "building tree 176 of 336\n",
      "building tree 177 of 336\n",
      "building tree 178 of 336\n",
      "building tree 179 of 336building tree 180 of 336\n",
      "\n",
      "building tree 181 of 336\n",
      "building tree 182 of 336\n",
      "building tree 183 of 336\n",
      "building tree 184 of 336\n",
      "building tree 185 of 336\n",
      "building tree 186 of 336\n",
      "building tree 187 of 336\n",
      "building tree 188 of 336\n",
      "building tree 189 of 336\n",
      "building tree 190 of 336\n",
      "building tree 191 of 336\n",
      "building tree 192 of 336\n",
      "building tree 193 of 336\n",
      "building tree 194 of 336\n",
      "building tree 195 of 336\n",
      "building tree 196 of 336\n",
      "building tree 197 of 336\n",
      "building tree 198 of 336\n",
      "building tree 199 of 336\n",
      "building tree 200 of 336\n",
      "building tree 201 of 336\n",
      "building tree 202 of 336\n",
      "building tree 203 of 336\n",
      "building tree 204 of 336\n",
      "building tree 205 of 336\n",
      "building tree 206 of 336\n",
      "building tree 207 of 336\n",
      "building tree 208 of 336\n",
      "building tree 209 of 336\n",
      "building tree 210 of 336\n",
      "building tree 211 of 336\n",
      "building tree 212 of 336\n",
      "building tree 213 of 336\n",
      "building tree 214 of 336\n",
      "building tree 215 of 336\n",
      "building tree 216 of 336\n",
      "building tree 217 of 336\n",
      "building tree 218 of 336\n",
      "building tree 219 of 336\n",
      "building tree 220 of 336\n",
      "building tree 221 of 336\n",
      "building tree 222 of 336\n",
      "building tree 223 of 336\n",
      "building tree 224 of 336\n",
      "building tree 225 of 336\n",
      "building tree 226 of 336\n",
      "building tree 227 of 336\n",
      "building tree 228 of 336\n",
      "building tree 229 of 336\n",
      "building tree 230 of 336\n",
      "building tree 231 of 336\n",
      "building tree 232 of 336\n",
      "building tree 233 of 336\n",
      "building tree 234 of 336\n",
      "building tree 235 of 336\n",
      "building tree 236 of 336\n",
      "building tree 237 of 336\n",
      "building tree 238 of 336\n",
      "building tree 239 of 336\n",
      "building tree 240 of 336\n",
      "building tree 241 of 336\n",
      "building tree 242 of 336\n",
      "building tree 243 of 336\n",
      "building tree 244 of 336\n",
      "building tree 245 of 336\n",
      "building tree 246 of 336\n",
      "building tree 247 of 336\n",
      "building tree 248 of 336\n",
      "building tree 249 of 336\n",
      "building tree 250 of 336\n",
      "building tree 251 of 336\n",
      "building tree 252 of 336\n",
      "building tree 253 of 336\n",
      "building tree 254 of 336\n",
      "building tree 255 of 336\n",
      "building tree 256 of 336\n",
      "building tree 257 of 336\n",
      "building tree 258 of 336\n",
      "building tree 259 of 336\n",
      "building tree 260 of 336\n",
      "building tree 261 of 336\n",
      "building tree 262 of 336\n",
      "building tree 263 of 336\n",
      "building tree 264 of 336\n",
      "building tree 265 of 336\n",
      "building tree 266 of 336\n",
      "building tree 267 of 336\n",
      "building tree 268 of 336\n",
      "building tree 269 of 336\n",
      "building tree 270 of 336\n",
      "building tree 271 of 336\n",
      "building tree 272 of 336\n",
      "building tree 273 of 336\n",
      "building tree 274 of 336\n",
      "building tree 275 of 336\n",
      "building tree 276 of 336\n",
      "building tree 277 of 336\n",
      "building tree 278 of 336\n",
      "building tree 279 of 336\n",
      "building tree 280 of 336\n",
      "building tree 281 of 336\n",
      "building tree 282 of 336\n",
      "building tree 283 of 336\n",
      "building tree 284 of 336\n",
      "building tree 285 of 336\n",
      "building tree 286 of 336\n",
      "building tree 287 of 336\n",
      "building tree 288 of 336\n",
      "building tree 289 of 336\n",
      "building tree 290 of 336\n",
      "building tree 291 of 336\n",
      "building tree 292 of 336\n",
      "building tree 293 of 336\n",
      "building tree 294 of 336\n",
      "building tree 295 of 336\n",
      "building tree 296 of 336\n",
      "building tree 297 of 336\n",
      "building tree 298 of 336\n",
      "building tree 299 of 336building tree 300 of 336\n",
      "\n",
      "building tree 301 of 336\n",
      "building tree 302 of 336\n",
      "building tree 303 of 336\n",
      "building tree 304 of 336\n",
      "building tree 305 of 336\n",
      "building tree 306 of 336\n",
      "building tree 307 of 336building tree 308 of 336\n",
      "\n",
      "building tree 309 of 336\n",
      "building tree 310 of 336\n",
      "building tree 311 of 336\n",
      "building tree 312 of 336\n",
      "building tree 313 of 336\n",
      "building tree 314 of 336\n",
      "building tree 315 of 336\n",
      "building tree 316 of 336\n",
      "building tree 317 of 336\n",
      "building tree 318 of 336\n",
      "building tree 319 of 336\n",
      "building tree 320 of 336\n",
      "building tree 321 of 336\n",
      "building tree 322 of 336\n",
      "building tree 323 of 336\n",
      "building tree 324 of 336\n",
      "building tree 325 of 336\n",
      "building tree 326 of 336\n",
      "building tree 327 of 336\n",
      "building tree 328 of 336\n",
      "building tree 329 of 336\n",
      "building tree 330 of 336\n",
      "building tree 331 of 336\n",
      "building tree 332 of 336\n",
      "building tree 333 of 336\n",
      "building tree 334 of 336\n",
      "building tree 335 of 336\n",
      "building tree 336 of 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 336 out of 336 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando  {'caso': 1, 'geocode': 1, 'scaler': 'Standard'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=2)]: Done 336 out of 336 | elapsed:    3.8s finished\n",
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "final.fit(train_values,train_labels)\n",
    "test_data=final.predict(test_values)\n",
    "pvalues=test_values[['geo_level_1_id']].copy()\n",
    "pvalues['damage_grade']=test_data\n",
    "pvalues=pvalues.drop(['geo_level_1_id'],axis=1)\n",
    "pvalues.to_csv(DATA_DIR / 'submission_NN_00_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
