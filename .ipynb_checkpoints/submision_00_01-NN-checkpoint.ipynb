{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data', 'final', 'public')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializamodelo(caso):\n",
    "    global legeo,lencoder,lencoder_col\n",
    "    if 'legeo' in globals():\n",
    "        del legeo\n",
    "    if 'lencoder' in globals():    \n",
    "        del lencoder\n",
    "    if 'lencoder_col' in globals():\n",
    "        del lencoder_col\n",
    "    lencoder_col=list([])\n",
    "    if caso == 1:\n",
    "        legeo = LabelEncoder()\n",
    "        lencoder= list([])\n",
    "        print(\"Inicializa LabelEncoder caso 1\")\n",
    "    if caso == 2:\n",
    "        legeo = LabelEncoder()\n",
    "        lencoder= OneHotEncoder(handle_unknown='ignore', sparse=False)   \n",
    "        print(\"Inicializa OneHotEncoder caso 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepros(ltrain,lytrain,caso):\n",
    "    AGELIMIT=100\n",
    "    global legeo,lencoder,lencoder_col\n",
    "    s = (ltrain.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    s = (ltrain.dtypes != 'object')\n",
    "    number_cols = list(s[s].index)\n",
    "    if caso == 1:\n",
    "            inicializamodelo(caso)\n",
    "            contador=0\n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            for col in ltrain[object_cols].columns:\n",
    "                lencoder.append(LabelEncoder())\n",
    "                lencoder[contador].fit(ltrain[col])\n",
    "                lsns_data[col]=lencoder[contador].transform(ltrain[col])  \n",
    "                contador=contador+1\n",
    "    if caso == -1:\n",
    "            contador=0\n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            for col in ltrain[object_cols].columns:\n",
    "                lsns_data[col]=lencoder[contador].transform(ltrain[col])  \n",
    "                contador=contador+1               \n",
    "    if caso == 2:  \n",
    "            inicializamodelo(caso)\n",
    "            nada = lencoder.fit_transform(ltrain[object_cols])\n",
    "            co1c=0\n",
    "            for co1 in lencoder.categories_:\n",
    "                for co2 in co1:\n",
    "                    lencoder_col.append(object_cols[co1c]+\"_\"+co2)\n",
    "                co1c=co1c+1\n",
    "            lsns_data=pd.concat([ltrain[number_cols].copy(),\n",
    "                                 pd.DataFrame(nada,columns=lencoder_col,\n",
    "                                         index=ltrain[object_cols].index.tolist())],axis=1)\n",
    "    if caso == -2:  \n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            nada = lencoder.transform(ltrain[object_cols])\n",
    "            lsns_data=pd.concat([ltrain[number_cols].copy(),\n",
    "                                 pd.DataFrame(nada,columns=lencoder_col,\n",
    "                                         index=ltrain[object_cols].index.tolist())],axis=1)        \n",
    "    \n",
    "#    geo_level_1_fact=math.pow(10,int(math.log(lsns_data['geo_level_2_id'].max(),10)+1))\n",
    "#    geo_level_2_fact=math.pow(10,int(math.log(lsns_data['geo_level_3_id'].max(),10)+1))\n",
    "#    lsns_data['geo_level_n']=  lsns_data['geo_level_1_id']*geo_level_1_fact*geo_level_2_fact+lsns_data['geo_level_2_id']*geo_level_2_fact+lsns_data['geo_level_3_id']\n",
    "#    lsns_data['geo_level']=lsns_data['geo_level_n'].astype(np.int64).astype(str)\n",
    "#    legeo.fit(lsns_data['geo_level'])\n",
    "#    lsns_data['geo_level_cod']=legeo.transform(lsns_data['geo_level'])\n",
    "#    lsns_data=lsns_data.drop(['geo_level_1_id','geo_level_2_id','geo_level_3_id','geo_level_n','geo_level'],axis=1)\n",
    "    lsns_data=lsns_data.drop(['geo_level_2_id','geo_level_3_id'],axis=1)\n",
    "    lsns_data=lsns_data.join(lytrain)\n",
    "#    lsns_data=lsns_data[lsns_data.age<AGELIMIT]\n",
    "    lsytrain=lsns_data['damage_grade']\n",
    "    lsns_data=lsns_data.drop(['damage_grade'],axis=1)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    lsns_data[list(lsns_data.columns)]=min_max_scaler.fit_transform(lsns_data.values)\n",
    "    lcolum_x = list(lsns_data.columns)\n",
    "    return(lsns_data,lsytrain,lcolum_x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializa LabelEncoder caso 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(260601, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns_data,nada,colum_x=prepros(train_values,train_labels,1)\n",
    "sns_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargamodelo(modelcaso):\n",
    "    global model\n",
    "    if modelcaso==1:\n",
    "        model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial',max_iter=500)\n",
    "    if modelcaso==2:    \n",
    "        model = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\n",
    "    if modelcaso==3:\n",
    "        model = DecisionTreeClassifier(random_state=0) \n",
    "    if modelcaso==4:\n",
    "        model = MultinomialNB\n",
    "    if modelcaso==5:\n",
    "        model = DecisionTreeRegressor(random_state=0)   \n",
    "    if modelcaso==6:\n",
    "        model = SVC(gamma='auto')          \n",
    "    if modelcaso==9:    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=36, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(15, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_values, train_labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializa LabelEncoder caso 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for mi in [6]:\n",
    "    cargamodelo(mi)\n",
    "    for micaso in [1,2]:\n",
    "        pred_data,y_train1,colum_x=prepros(X_train,y_train,micaso)\n",
    "        model.fit(pred_data,y_train1)\n",
    "        lcolum_f = list(X_train.columns)\n",
    "        test_data,y_test1,column_t=prepros(X_test,y_test,-micaso)\n",
    "        f1=f1_score(y_test1, model.predict(test_data).round(), average='micro')  \n",
    "        print('Modelo',mi,'Caso:',micaso,'F1_score:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamodelo(3)\n",
    "#pred_data,pred_label,colum_x=prepros(train_values,train_labels,2)\n",
    "#model.fit(pred_data,pred_label)\n",
    "#lcolum_f = list(test_values.columns)\n",
    "#print('Shapes',pred_data.shape,pred_label.shape)\n",
    "#pvalues,plabels,lcolum_f1=prepros(test_values,pd.DataFrame(pvalues['geo_level_1_id'],columns=['damage_grade']),-2)\n",
    "#print('Shapes',pvalues.shape,plabels.shape)\n",
    "#pvalues['damage_grade']=model.predict(pvalues)\n",
    "#pvalues=pvalues.drop(lcolum_f1,axis=1)\n",
    "#pvalues.to_csv(DATA_DIR / 'submission_00_02.csv')\n",
    "#test desde local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
