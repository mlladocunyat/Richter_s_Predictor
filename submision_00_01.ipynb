{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data', 'final', 'public')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializamodelo(caso):\n",
    "    global legeo,lencoder,lencoder_col\n",
    "    if 'legeo' in globals():\n",
    "        del legeo\n",
    "    if 'lencoder' in globals():    \n",
    "        del lencoder\n",
    "    if 'lencoder_col' in globals():\n",
    "        del lencoder_col\n",
    "    lencoder_col=list([])\n",
    "    if caso == 1:\n",
    "        legeo = LabelEncoder()\n",
    "        lencoder= list([])\n",
    "        print(\"Inicializa LabelEncoder caso 1\")\n",
    "    if caso == 2:\n",
    "        legeo = LabelEncoder()\n",
    "        lencoder= OneHotEncoder(handle_unknown='ignore', sparse=False)   \n",
    "        print(\"Inicializa OneHotEncoder caso 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepros(ltrain,caso):\n",
    "    AGELIMIT=100\n",
    "    global legeo,lencoder,lencoder_col\n",
    "    s = (ltrain.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    s = (ltrain.dtypes != 'object')\n",
    "    number_cols = list(s[s].index)\n",
    "    if caso == 1:\n",
    "            inicializamodelo(caso)\n",
    "            contador=0\n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            for col in ltrain[object_cols].columns:\n",
    "                lencoder.append(LabelEncoder())\n",
    "                lencoder[contador].fit(ltrain[col])\n",
    "                lsns_data[col]=lencoder[contador].transform(ltrain[col])  \n",
    "                contador=contador+1\n",
    "    if caso == -1:\n",
    "            contador=0\n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            for col in ltrain[object_cols].columns:\n",
    "                lsns_data[col]=lencoder[contador].transform(ltrain[col])  \n",
    "                contador=contador+1               \n",
    "    if caso == 2:  \n",
    "            inicializamodelo(caso)\n",
    "            nada = lencoder.fit_transform(ltrain[object_cols])\n",
    "            co1c=0\n",
    "            for co1 in lencoder.categories_:\n",
    "                for co2 in co1:\n",
    "                    lencoder_col.append(object_cols[co1c]+\"_\"+co2)\n",
    "                co1c=co1c+1\n",
    "            lsns_data=pd.concat([ltrain[number_cols].copy(),\n",
    "                                 pd.DataFrame(nada,columns=lencoder_col,\n",
    "                                         index=ltrain[object_cols].index.tolist())],axis=1)\n",
    "    if caso == -2:  \n",
    "            lsns_data=ltrain[number_cols].copy()\n",
    "            nada = lencoder.transform(ltrain[object_cols])\n",
    "            lsns_data=pd.concat([ltrain[number_cols].copy(),\n",
    "                                 pd.DataFrame(nada,columns=lencoder_col,\n",
    "                                         index=ltrain[object_cols].index.tolist())],axis=1)        \n",
    "    \n",
    "    geo_level_1_fact=math.pow(10,int(math.log(lsns_data['geo_level_2_id'].max(),10)+1))\n",
    "    geo_level_2_fact=math.pow(10,int(math.log(lsns_data['geo_level_3_id'].max(),10)+1))\n",
    "    lsns_data['geo_level_n']=  lsns_data['geo_level_1_id']*geo_level_1_fact*geo_level_2_fact+lsns_data['geo_level_2_id']*geo_level_2_fact+lsns_data['geo_level_3_id']\n",
    "    lsns_data['geo_level']=lsns_data['geo_level_n'].astype(np.int64).astype(str)\n",
    "    legeo.fit(lsns_data['geo_level'])\n",
    "    lsns_data['geo_level_cod']=legeo.transform(lsns_data['geo_level'])\n",
    "    lsns_data=lsns_data.drop(['geo_level_1_id','geo_level_2_id','geo_level_3_id','geo_level_n','geo_level'],axis=1)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    lsns_data[list(lsns_data.columns)]=min_max_scaler.fit_transform(lsns_data.values)\n",
    "    lcolum_x = list(lsns_data.columns)\n",
    "    return(lsns_data,lcolum_x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializa LabelEncoder caso 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "sns_data,colum_x=prepros(train_values,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial',max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_values, train_labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializa LabelEncoder caso 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.5787044035395761\n"
     ]
    }
   ],
   "source": [
    "micaso=2\n",
    "pred_data,colum_x=prepros(X_train,micaso)\n",
    "model.fit(pred_data,y_train)\n",
    "lcolum_f = list(X_train.columns)\n",
    "test_data,column_t=prepros(X_test,-micaso)\n",
    "f1=f1_score(y_test, model.predict(test_data), average='micro')  \n",
    "print('F1_score:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data,colum_x=prepros(train_values,1)\n",
    "model.fit(pred_data,train_labels)\n",
    "lcolum_f = list(test_values.columns)\n",
    "pvalues=test_values.copy()\n",
    "pvalues['damage_grade']=model.predict(pred_data)\n",
    "pvalues=pvalues.drop(lcolum_f,axis=1)\n",
    "pvalues.to_csv(DATA_DIR / 'submission_00_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
